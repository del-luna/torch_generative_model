{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_mnist_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "73QbmmgQ_-3p",
        "colab_type": "code",
        "outputId": "1e173370-3eb2-428e-dd80-f974aafe2d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok_1vfitANtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ned2pVyA-9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "lr = 0.0002\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = datasets.MNIST(root='./mnist_data/', train=True,\n",
        "                               transform=transform, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,\n",
        "                                          shuffle=True, drop_last=True)\n",
        "testset = datasets.MNIST(root='./mnist_data/', train=False,\n",
        "                               transform=transform, download=True)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size=batch_size,\n",
        "                                          shuffle=False, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1H580kcwfcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHKo347OBD27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_size, n_class):\n",
        "    super(Generator, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size,256) # 100, 256\n",
        "    self.fc2 = nn.Linear(256,512)\n",
        "    self.fc3 = nn.Linear(512, 1024)\n",
        "    self.fc4 = nn.Linear(1024, n_class) # 1024, 28*28\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "    x = F.tanh(self.fc4(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_size, n_class):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 1024) # 28*28, 1024\n",
        "    self.fc2 = nn.Linear(1024,512)\n",
        "    self.fc3 = nn.Linear(512,256)\n",
        "    self.fc4 = nn.Linear(256, n_class) # 256, 1\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "    x = F.dropout(x, 0.3)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "    x = F.dropout(x, 0.3)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "    x = F.dropout(x, 0.3)\n",
        "    x = F.sigmoid(self.fc4(x))\n",
        "\n",
        "    return x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QErExWaDCPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "G = Generator(input_size = 100, n_class=28*28).to(device)\n",
        "D = Discriminator(input_size=28*28, n_class=1).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFb9fRiqDOzo",
        "colab_type": "code",
        "outputId": "be7063e5-aa4c-4f6b-b05f-f4cb505a6a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "G"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
              "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYRe60JAQ3GD",
        "colab_type": "code",
        "outputId": "16c5ef8b-d2ff-4a1e-b2fe-88380263ed47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "D"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InWnhgevQ4VT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BCE_loss = nn.BCELoss()\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koi_emH-Rotv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def D_train(x):\n",
        "  D.zero_grad()\n",
        "\n",
        "  x_real, y_real = x.view(-1,784), torch.ones(batch_size, 1)\n",
        "  x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "  D_output = D(x_real)\n",
        "  D_real_loss = BCE_loss(D_output, y_real)\n",
        "  D_real_score = D_output\n",
        "\n",
        "  z = Variable(torch.randn(batch_size, 100).to(device))\n",
        "  x_fake, y_fake = G(z), Variable(torch.zeros(batch_size, 1).to(device))\n",
        "\n",
        "  D_output = D(x_fake)\n",
        "  D_fake_loss = BCE_loss(D_output, y_fake)\n",
        "  D_fake_score = D_output\n",
        "\n",
        "  D_loss = D_real_loss + D_fake_loss\n",
        "  D_loss.backward()\n",
        "  D_optimizer.step()\n",
        "\n",
        "  return D_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC4F1SwgDBnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_train(x):\n",
        "  G.zero_grad()\n",
        "\n",
        "  z = Variable(torch.randn(batch_size, 100).to(device))\n",
        "  y = Variable(torch.ones(batch_size, 1).to(device))\n",
        "\n",
        "  G_output = G(z)\n",
        "  D_output = D(G_output)\n",
        "  G_loss = BCE_loss(D_output, y)\n",
        "\n",
        "  G_loss.backward()\n",
        "  G_optimizer.step()\n",
        "\n",
        "  return G_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4meUw0uEO1P5",
        "colab_type": "code",
        "outputId": "b85e07da-a0bd-4af6-f291-557e97daf624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "total_epoch = 100\n",
        "for epoch in range(1, total_epoch+1):\n",
        "  D_loss_hist, G_loss_hist = [], []\n",
        "  for batch_idx, (x, _) in enumerate(trainloader):\n",
        "    D_loss_hist.append(D_train(x))\n",
        "    G_loss_hist.append(G_train(x))\n",
        "\n",
        "  print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % ((epoch), total_epoch, torch.mean(torch.FloatTensor(D_loss_hist)), torch.mean(torch.FloatTensor(G_loss_hist))))\n",
        "  \n",
        "  if (epoch+1)%5==0:\n",
        "    sample = G(Variable(torch.randn(batch_size, 100).to(device)))\n",
        "    save_image(sample.view(sample.size(0),1,28,28), \"/gdrive/My Drive/Pytorch/GAN/\"+str(epoch)+'.png')\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/100]: loss_d: 1.200, loss_g: 1.029\n",
            "[2/100]: loss_d: 1.201, loss_g: 1.030\n",
            "[3/100]: loss_d: 1.202, loss_g: 1.017\n",
            "[4/100]: loss_d: 1.193, loss_g: 1.036\n",
            "[5/100]: loss_d: 1.213, loss_g: 1.009\n",
            "[6/100]: loss_d: 1.202, loss_g: 1.037\n",
            "[7/100]: loss_d: 1.207, loss_g: 1.020\n",
            "[8/100]: loss_d: 1.220, loss_g: 0.986\n",
            "[9/100]: loss_d: 1.230, loss_g: 0.963\n",
            "[10/100]: loss_d: 1.225, loss_g: 0.982\n",
            "[11/100]: loss_d: 1.227, loss_g: 0.990\n",
            "[12/100]: loss_d: 1.214, loss_g: 1.001\n",
            "[13/100]: loss_d: 1.211, loss_g: 1.020\n",
            "[14/100]: loss_d: 1.221, loss_g: 0.987\n",
            "[15/100]: loss_d: 1.220, loss_g: 0.996\n",
            "[16/100]: loss_d: 1.229, loss_g: 0.970\n",
            "[17/100]: loss_d: 1.226, loss_g: 0.993\n",
            "[18/100]: loss_d: 1.237, loss_g: 0.964\n",
            "[19/100]: loss_d: 1.232, loss_g: 0.966\n",
            "[20/100]: loss_d: 1.230, loss_g: 0.973\n",
            "[21/100]: loss_d: 1.231, loss_g: 0.975\n",
            "[22/100]: loss_d: 1.235, loss_g: 0.976\n",
            "[23/100]: loss_d: 1.238, loss_g: 0.956\n",
            "[24/100]: loss_d: 1.234, loss_g: 0.971\n",
            "[25/100]: loss_d: 1.236, loss_g: 0.965\n",
            "[26/100]: loss_d: 1.240, loss_g: 0.949\n",
            "[27/100]: loss_d: 1.246, loss_g: 0.954\n",
            "[28/100]: loss_d: 1.236, loss_g: 0.968\n",
            "[29/100]: loss_d: 1.238, loss_g: 0.959\n",
            "[30/100]: loss_d: 1.238, loss_g: 0.962\n",
            "[31/100]: loss_d: 1.245, loss_g: 0.953\n",
            "[32/100]: loss_d: 1.250, loss_g: 0.941\n",
            "[33/100]: loss_d: 1.236, loss_g: 0.967\n",
            "[34/100]: loss_d: 1.246, loss_g: 0.944\n",
            "[35/100]: loss_d: 1.251, loss_g: 0.941\n",
            "[36/100]: loss_d: 1.249, loss_g: 0.942\n",
            "[37/100]: loss_d: 1.248, loss_g: 0.945\n",
            "[38/100]: loss_d: 1.251, loss_g: 0.953\n",
            "[39/100]: loss_d: 1.251, loss_g: 0.945\n",
            "[40/100]: loss_d: 1.258, loss_g: 0.929\n",
            "[41/100]: loss_d: 1.260, loss_g: 0.933\n",
            "[42/100]: loss_d: 1.256, loss_g: 0.917\n",
            "[43/100]: loss_d: 1.261, loss_g: 0.926\n",
            "[44/100]: loss_d: 1.256, loss_g: 0.932\n",
            "[45/100]: loss_d: 1.264, loss_g: 0.921\n",
            "[46/100]: loss_d: 1.259, loss_g: 0.924\n",
            "[47/100]: loss_d: 1.268, loss_g: 0.912\n",
            "[48/100]: loss_d: 1.270, loss_g: 0.913\n",
            "[49/100]: loss_d: 1.254, loss_g: 0.951\n",
            "[50/100]: loss_d: 1.257, loss_g: 0.930\n",
            "[51/100]: loss_d: 1.268, loss_g: 0.907\n",
            "[52/100]: loss_d: 1.271, loss_g: 0.905\n",
            "[53/100]: loss_d: 1.269, loss_g: 0.910\n",
            "[54/100]: loss_d: 1.271, loss_g: 0.906\n",
            "[55/100]: loss_d: 1.277, loss_g: 0.889\n",
            "[56/100]: loss_d: 1.268, loss_g: 0.907\n",
            "[57/100]: loss_d: 1.270, loss_g: 0.919\n",
            "[58/100]: loss_d: 1.271, loss_g: 0.905\n",
            "[59/100]: loss_d: 1.281, loss_g: 0.884\n",
            "[60/100]: loss_d: 1.277, loss_g: 0.905\n",
            "[61/100]: loss_d: 1.271, loss_g: 0.904\n",
            "[62/100]: loss_d: 1.273, loss_g: 0.902\n",
            "[63/100]: loss_d: 1.266, loss_g: 0.905\n",
            "[64/100]: loss_d: 1.268, loss_g: 0.905\n",
            "[65/100]: loss_d: 1.275, loss_g: 0.905\n",
            "[66/100]: loss_d: 1.263, loss_g: 0.922\n",
            "[67/100]: loss_d: 1.277, loss_g: 0.888\n",
            "[68/100]: loss_d: 1.276, loss_g: 0.893\n",
            "[69/100]: loss_d: 1.266, loss_g: 0.915\n",
            "[70/100]: loss_d: 1.276, loss_g: 0.900\n",
            "[71/100]: loss_d: 1.278, loss_g: 0.888\n",
            "[72/100]: loss_d: 1.277, loss_g: 0.895\n",
            "[73/100]: loss_d: 1.273, loss_g: 0.897\n",
            "[74/100]: loss_d: 1.271, loss_g: 0.902\n",
            "[75/100]: loss_d: 1.272, loss_g: 0.898\n",
            "[76/100]: loss_d: 1.281, loss_g: 0.891\n",
            "[77/100]: loss_d: 1.275, loss_g: 0.900\n",
            "[78/100]: loss_d: 1.284, loss_g: 0.888\n",
            "[79/100]: loss_d: 1.276, loss_g: 0.896\n",
            "[80/100]: loss_d: 1.277, loss_g: 0.898\n",
            "[81/100]: loss_d: 1.271, loss_g: 0.907\n",
            "[82/100]: loss_d: 1.278, loss_g: 0.887\n",
            "[83/100]: loss_d: 1.280, loss_g: 0.889\n",
            "[84/100]: loss_d: 1.283, loss_g: 0.880\n",
            "[85/100]: loss_d: 1.282, loss_g: 0.898\n",
            "[86/100]: loss_d: 1.273, loss_g: 0.912\n",
            "[87/100]: loss_d: 1.278, loss_g: 0.894\n",
            "[88/100]: loss_d: 1.282, loss_g: 0.886\n",
            "[89/100]: loss_d: 1.280, loss_g: 0.886\n",
            "[90/100]: loss_d: 1.280, loss_g: 0.900\n",
            "[91/100]: loss_d: 1.274, loss_g: 0.894\n",
            "[92/100]: loss_d: 1.280, loss_g: 0.890\n",
            "[93/100]: loss_d: 1.279, loss_g: 0.890\n",
            "[94/100]: loss_d: 1.284, loss_g: 0.878\n",
            "[95/100]: loss_d: 1.282, loss_g: 0.888\n",
            "[96/100]: loss_d: 1.284, loss_g: 0.882\n",
            "[97/100]: loss_d: 1.290, loss_g: 0.874\n",
            "[98/100]: loss_d: 1.287, loss_g: 0.869\n",
            "[99/100]: loss_d: 1.280, loss_g: 0.887\n",
            "[100/100]: loss_d: 1.281, loss_g: 0.881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reLKjl6kPgYB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1JzmrppnrHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}